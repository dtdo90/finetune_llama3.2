{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b32d521-09e7-4118-8215-b878bcdd24e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T02:15:13.512912Z",
     "iopub.status.busy": "2025-01-09T02:15:13.512437Z",
     "iopub.status.idle": "2025-01-09T02:15:21.377032Z",
     "shell.execute_reply": "2025-01-09T02:15:21.376428Z",
     "shell.execute_reply.started": "2025-01-09T02:15:13.512890Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.2.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (15.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.0)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2023.6.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.9.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.27.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from datasets) (5.4.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.32.2->datasets) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.32.2->datasets) (2020.6.20)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas->datasets) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2023.4)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: trl in /usr/local/lib/python3.11/dist-packages (0.13.0)\n",
      "Requirement already satisfied: accelerate>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from trl) (1.2.1)\n",
      "Requirement already satisfied: datasets>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from trl) (3.2.0)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from trl) (13.9.4)\n",
      "Requirement already satisfied: transformers>=4.46.0 in /usr/local/lib/python3.11/dist-packages (from trl) (4.47.1)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl) (23.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in /usr/lib/python3/dist-packages (from accelerate>=0.34.0->trl) (5.4.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl) (2.1.1+cu121)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl) (0.27.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl) (0.5.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.21.0->trl) (3.13.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.21.0->trl) (15.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.21.0->trl) (0.3.7)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=2.21.0->trl) (2.2.0)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.21.0->trl) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.21.0->trl) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=2.21.0->trl) (3.4.1)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.21.0->trl) (0.70.15)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets>=2.21.0->trl) (2023.6.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.21.0->trl) (3.9.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.46.0->trl) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.46.0->trl) (0.21.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl) (2.17.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.21.0->trl) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.21.0->trl) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.21.0->trl) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.21.0->trl) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.21.0->trl) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate>=0.34.0->trl) (4.9.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->trl) (0.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.21.0->trl) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.32.2->datasets>=2.21.0->trl) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.21.0->trl) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.32.2->datasets>=2.21.0->trl) (2020.6.20)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate>=0.34.0->trl) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate>=0.34.0->trl) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate>=0.34.0->trl) (3.1.3)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate>=0.34.0->trl) (2.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.21.0->trl) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas->datasets>=2.21.0->trl) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.21.0->trl) (2023.4)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.21.0->trl) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.10.0->accelerate>=0.34.0->trl) (2.1.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=1.10.0->accelerate>=0.34.0->trl) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.6.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from peft) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from peft) (23.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in /usr/lib/python3/dist-packages (from peft) (5.4.1)\n",
      "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from peft) (2.1.1+cu121)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from peft) (4.47.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from peft) (4.67.1)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from peft) (1.2.1)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from peft) (0.5.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.21.0->peft) (0.27.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (4.9.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (2023.6.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (2.1.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->peft) (2023.12.25)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers->peft) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->peft) (0.21.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->peft) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers->peft) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->peft) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->transformers->peft) (2020.6.20)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install datasets\n",
    "!pip install trl\n",
    "!pip install peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7fc321a-000b-40ec-8b32-c563a9284b06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T02:15:21.380476Z",
     "iopub.status.busy": "2025-01-09T02:15:21.380288Z",
     "iopub.status.idle": "2025-01-09T02:15:21.685123Z",
     "shell.execute_reply": "2025-01-09T02:15:21.684680Z",
     "shell.execute_reply.started": "2025-01-09T02:15:21.380472Z"
    }
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "import json\n",
    "\n",
    "with open(\"config.json\", \"r\") as config_file:\n",
    "    config = json.load(config_file)\n",
    "    access_token = config[\"HF_ACCESS_TOKEN\"]\n",
    "\n",
    "login(token=access_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe92c1c5-2a0d-4d6e-af8e-f765ada9f6d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T02:15:21.691208Z",
     "iopub.status.busy": "2025-01-09T02:15:21.687983Z",
     "iopub.status.idle": "2025-01-09T02:15:29.445842Z",
     "shell.execute_reply": "2025-01-09T02:15:29.445314Z",
     "shell.execute_reply.started": "2025-01-09T02:15:21.691184Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 02:15:24.974573: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-01-09 02:15:24.974627: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-01-09 02:15:24.975660: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-09 02:15:24.981234: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-09 02:15:25.818655: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "from datasets.arrow_dataset import Dataset\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig\n",
    "from peft import AutoPeftModelForCausalLM\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    AutoTokenizer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "\n",
    "from trl import SFTTrainer\n",
    "from argparse import Namespace\n",
    "\n",
    "\n",
    "script_args = Namespace(\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    gradient_accumulation_steps=4,\n",
    "    learning_rate=3e-4,\n",
    "    max_grad_norm=0.3,\n",
    "    weight_decay=0.01,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.0,\n",
    "    lora_r=8,\n",
    "    max_seq_length=256,\n",
    "    model_name=\"meta-llama/Llama-3.2-1B-Instruct\",\n",
    "    tokenizer_path=\"tokenizer.model\",\n",
    "    # dataset_name=\"tatsu-lab/alpaca\",\n",
    "    dataset_name=\"instruction-data.json\",\n",
    "    device_map=\"cuda\",\n",
    "    use_4bit=True,\n",
    "    bnb_4bit_compute_dtype=\"float16\",\n",
    "    num_train_epochs=10,\n",
    "    fp16=False,\n",
    "    bf16=True,\n",
    "    optim=\"adamw_torch\",\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    max_steps=200,\n",
    "    warmup_steps=50,\n",
    "    group_by_length=True, # Group sequences into batches with same length\n",
    "    eval_steps=10,\n",
    "    save_steps=10,\n",
    "    logging_steps=10, # Log every X updates steps\n",
    "    report_to=\"wandb\",\n",
    "    output_dir=\"./results_packing\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af546e6c-d5c6-4960-8b4d-e5a9d3fdcd85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T02:15:29.447195Z",
     "iopub.status.busy": "2025-01-09T02:15:29.446946Z",
     "iopub.status.idle": "2025-01-09T02:15:29.491624Z",
     "shell.execute_reply": "2025-01-09T02:15:29.491185Z",
     "shell.execute_reply.started": "2025-01-09T02:15:29.447169Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data saved to instruction-data-train.json\n",
      "Validation data saved to instruction-data-val.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def split_data(args):\n",
    "    \"\"\" Split the saved data into train and val\"\"\"\n",
    "    with open(args.dataset_name,\"r\") as f:\n",
    "        ds=json.load(f)\n",
    "    train_split=int(0.9*len(ds))\n",
    "    ds_train=ds[:train_split]\n",
    "    ds_val=ds[train_split:]\n",
    "\n",
    "    # write into json file\n",
    "    train_file=\"instruction-data-train.json\"\n",
    "    val_file=\"instruction-data-val.json\"\n",
    "\n",
    "    with open(train_file, \"w\") as train_f:\n",
    "        json.dump(ds_train, train_f, indent=4)\n",
    "    print(f\"Training data saved to {train_file}\")\n",
    "\n",
    "    # write validation data to a JSON file\n",
    "    with open(val_file, \"w\") as val_f:\n",
    "        json.dump(ds_val, val_f, indent=4)\n",
    "    print(f\"Validation data saved to {val_file}\")\n",
    "\n",
    "split_data(script_args)\n",
    "\n",
    "def gen_train_input():\n",
    "    \"\"\" Format all data input in alpaca style\n",
    "        Return: a data object which can be accessed via for loop\n",
    "    \"\"\"\n",
    "    # load data\n",
    "    data_file=\"instruction-data-train.json\"\n",
    "    with open(data_file,\"r\") as f:\n",
    "        ds= json.load(f)\n",
    "\n",
    "    for sample in iter(ds):\n",
    "        # extract instruction, input and output text\n",
    "        instruction=sample['instruction']\n",
    "        input_text=sample['input']\n",
    "        output_text=sample['output']\n",
    "        formatted_prompt=None\n",
    "\n",
    "        if input_text is None or input_text == \"\":\n",
    "            formatted_prompt=(\n",
    "                f\"<|start_header_id|>user<|end_header_id|>\\n\\n\"\n",
    "                f\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n\"\n",
    "                f\"### Instruction:\\n{instruction}\\n\\n\"\n",
    "                f\"### Response:\\n<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\" # format to signal the model's response\n",
    "                f\"{output_text}<|eot_id|><|end_of_text|>\"\n",
    "            )\n",
    "        else:\n",
    "            formatted_prompt=(\n",
    "                f\"<|start_header_id|>user<|end_header_id|>\\n\\n\"\n",
    "                f\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n\"\n",
    "                f\"### Instruction:\\n{instruction}\\n\\n### Input:\\n{input_text}\\n\\n\"\n",
    "                f\"### Response:\\n<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\"\n",
    "                f\"{output_text}<|eot_id|><|end_of_text|>\"\n",
    "            )\n",
    "        formatted_prompt=\"\".join(formatted_prompt) # exclude trailing white spaces\n",
    "        yield {'text': formatted_prompt}           # stream text into the dataloader, one by one\n",
    "\n",
    "        \n",
    "def gen_val_input():\n",
    "    \"\"\" Format all data input in alpaca style\n",
    "        Return: a data object which can be accessed via for loop\n",
    "    \"\"\"\n",
    "    # load data\n",
    "    data_file=\"instruction-data-val.json\"\n",
    "    with open(data_file,\"r\") as f:\n",
    "        ds= json.load(f)\n",
    "\n",
    "    for sample in iter(ds):\n",
    "        # extract instruction, input and output text\n",
    "        instruction=sample['instruction']\n",
    "        input_text=sample['input']\n",
    "        output_text=sample['output']\n",
    "        formatted_prompt=None\n",
    "\n",
    "        if input_text is None or input_text == \"\":\n",
    "            formatted_prompt=(\n",
    "                f\"<|start_header_id|>user<|end_header_id|>\\n\\n\"\n",
    "                f\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n\"\n",
    "                f\"### Instruction:\\n{instruction}\\n\\n\"\n",
    "                f\"### Response:\\n<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\" # format to signal the model's response\n",
    "                f\"{output_text}<|eot_id|><|end_of_text>|\"\n",
    "            )\n",
    "        else:\n",
    "            formatted_prompt=(\n",
    "                f\"<|start_header_id|>user<|end_header_id|>\\n\\n\"\n",
    "                f\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n\"\n",
    "                f\"### Instruction:\\n{instruction}\\n\\n### Input:\\n{input_text}\\n\\n\"\n",
    "                f\"### Response:\\n<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\"\n",
    "                f\"{output_text}<|eot_id|><|end_of_text|>\"\n",
    "            )\n",
    "        formatted_prompt=\"\".join(formatted_prompt) # exclude trailing white spaces\n",
    "        yield {'text': formatted_prompt} # stream text into the dataloader, one by one\n",
    "        \n",
    "train_gen = Dataset.from_generator(gen_train_input)\n",
    "val_gen=Dataset.from_generator(gen_val_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5585cafa-ffac-4701-8ba0-35a4aefd4b94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T02:15:29.492427Z",
     "iopub.status.busy": "2025-01-09T02:15:29.492267Z",
     "iopub.status.idle": "2025-01-09T02:15:34.009275Z",
     "shell.execute_reply": "2025-01-09T02:15:34.008679Z",
     "shell.execute_reply.started": "2025-01-09T02:15:29.492411Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_and_prepare_model(args):\n",
    "    device_map =\"auto\"\n",
    "    model=AutoModelForCausalLM.from_pretrained(\n",
    "        args.model_name,\n",
    "        # quantization_config=args.bnb_config,\n",
    "        device_map=args.device_map,\n",
    "        token=True\n",
    "    )\n",
    "\n",
    "    peft_config=LoraConfig(\n",
    "        lora_alpha=script_args.lora_alpha,\n",
    "        lora_dropout=script_args.lora_dropout,\n",
    "        r=script_args.lora_r,\n",
    "        bias=\"none\",\n",
    "        task_type=\"CAUSAL_LM\",\n",
    "        target_modules=['q_proj', 'k_proj', 'v_proj'],\n",
    "        # target_modules=[\"query_key_value\"]\n",
    "    )\n",
    "    tokenizer=AutoTokenizer.from_pretrained(script_args.model_name, trust_remote_code=True)\n",
    "    tokenizer.add_special_tokens\n",
    "    tokenizer.pad_token=\"<|end_of_text|>\" # this token is already available in tokenizer list\n",
    "    tokenizer.padding_side = \"right\"\n",
    "\n",
    "    return model,peft_config,tokenizer\n",
    "\n",
    "model,peft_config,tokenizer=create_and_prepare_model(script_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c6f6c0f-d644-4d7c-9027-36e11dd0304a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T02:15:35.680053Z",
     "iopub.status.busy": "2025-01-09T02:15:35.679562Z",
     "iopub.status.idle": "2025-01-09T02:17:08.037121Z",
     "shell.execute_reply": "2025-01-09T02:17:08.036618Z",
     "shell.execute_reply.started": "2025-01-09T02:15:35.680023Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e08df86345a4fcba6bbae5f6a45f43d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/110 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-01-09 02:15:36,114] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 01:29, Epoch 6/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.330800</td>\n",
       "      <td>3.688517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.069100</td>\n",
       "      <td>3.073312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.165100</td>\n",
       "      <td>2.045742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.165400</td>\n",
       "      <td>1.425161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.824600</td>\n",
       "      <td>1.313111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.745500</td>\n",
       "      <td>1.320160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.730700</td>\n",
       "      <td>1.308774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.725300</td>\n",
       "      <td>1.303558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.666600</td>\n",
       "      <td>1.297198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.671900</td>\n",
       "      <td>1.278009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.703500</td>\n",
       "      <td>1.263294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.660400</td>\n",
       "      <td>1.270353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.628400</td>\n",
       "      <td>1.274776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.657100</td>\n",
       "      <td>1.288972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.632300</td>\n",
       "      <td>1.294213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.629700</td>\n",
       "      <td>1.283713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.634800</td>\n",
       "      <td>1.284479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.624100</td>\n",
       "      <td>1.289135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.604100</td>\n",
       "      <td>1.291605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.595400</td>\n",
       "      <td>1.292594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=200, training_loss=1.023242733478546, metrics={'train_runtime': 91.3593, 'train_samples_per_second': 70.053, 'train_steps_per_second': 2.189, 'total_flos': 2323685094236160.0, 'train_loss': 1.023242733478546, 'epoch': 6.451612903225806})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_arguments=TrainingArguments(\n",
    "    output_dir=script_args.output_dir,\n",
    "    per_device_eval_batch_size=script_args.per_device_eval_batch_size,\n",
    "    gradient_accumulation_steps=script_args.gradient_accumulation_steps,\n",
    "    optim=script_args.optim,\n",
    "    save_steps=script_args.save_steps,\n",
    "    logging_steps=script_args.logging_steps,\n",
    "    learning_rate=script_args.learning_rate,\n",
    "    fp16=script_args.fp16,\n",
    "    bf16=script_args.bf16,\n",
    "    max_grad_norm=script_args.max_grad_norm,\n",
    "    max_steps=script_args.max_steps,\n",
    "    warmup_steps=script_args.warmup_steps,\n",
    "    group_by_length=script_args.group_by_length,\n",
    "    lr_scheduler_type=script_args.lr_scheduler_type,\n",
    "    report_to=\"none\", # prevent error with wandb\n",
    "    eval_strategy=\"steps\",  # Evaluate periodically\n",
    "    eval_steps=script_args.eval_steps,  # Perform evaluation every X steps\n",
    ")\n",
    "\n",
    "\n",
    "trainer=SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_gen,\n",
    "    eval_dataset=val_gen,\n",
    "    peft_config=peft_config,\n",
    "    #dataset_text_field=\"text\",\n",
    "    #max_seq_length=script_args.max_seq_length,\n",
    "    processing_class=tokenizer,\n",
    "    args=training_arguments,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102e10e0-28bb-46cd-97ca-0fdd575d96db",
   "metadata": {},
   "source": [
    "## Generate text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "163aed01-1b9e-4fae-a986-0cb820db3c6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T02:23:25.707529Z",
     "iopub.status.busy": "2025-01-09T02:23:25.707293Z",
     "iopub.status.idle": "2025-01-09T02:23:25.713109Z",
     "shell.execute_reply": "2025-01-09T02:23:25.712543Z",
     "shell.execute_reply.started": "2025-01-09T02:23:25.707480Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate(model, prompt, tokenizer, max_new_tokens, context_size=256, temperature=0.0, top_k=1, eos_id=[128001,128009]):\n",
    "    \"\"\" Generate till reaching max_new_tokens or till eos_id=<|end_of_text|>\"\"\"\n",
    "    # format prompt\n",
    "    # formatted_prompt=(\n",
    "    #     f\"<|start_header_id|>user<|end_header_id|>\\n\\n\"\n",
    "    #     f\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n\"\n",
    "    #     f\"### Instruction:\\n{prompt}\"\n",
    "    # )\n",
    "    formatted_prompt=(\n",
    "        f\"<|start_header_id|>user<|end_header_id|>\\n\\n\"\n",
    "        f\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n\"\n",
    "        f\"### Instruction:\\n{prompt}\"\n",
    "        f\"### Response:\\n<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\"\n",
    "    )\n",
    "    idx=tokenizer.encode(formatted_prompt)\n",
    "    idx=torch.tensor(idx).unsqueeze(0).to(script_args.device_map) # add batch dimension\n",
    "    _,num_tokens=idx.shape\n",
    "    #print(\"Number of input tokens: \",num_tokens)\n",
    "\n",
    "    # For-loop is the same as before: Get logits, and only focus on last time step\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            outputs = model.forward(idx_cond)\n",
    "            logits=outputs.logits\n",
    "        # last time step\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        # New: Filter logits with top_k sampling\n",
    "        if top_k is not None:\n",
    "            # Keep only top_k values\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(logits < min_val, torch.tensor(float('-inf')).to(logits.device), logits)\n",
    "\n",
    "        # New: Apply temperature scaling\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "\n",
    "            # Apply softmax to get probabilities\n",
    "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
    "\n",
    "            # Sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
    "\n",
    "        # Otherwise same as before: get idx of the vocab entry with the highest logits value\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
    "\n",
    "        if idx_next in eos_id:  # Stop generating early if <|eot_id|> or<|end_of_text|> token is encountered \n",
    "            break\n",
    "\n",
    "        # Same as before: append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
    "        \n",
    "    #print(f\"Output tensor: {idx.shape}\")\n",
    "    # remove batch dimension\n",
    "    idx_flat=idx.squeeze(0)\n",
    "    generated_ids=idx_flat[num_tokens:] # take out the input prompt\n",
    "    generated_text=tokenizer.decode(generated_ids)\n",
    "    \n",
    "    return generated_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da3888c9-9e84-4f1d-9b81-01f78b0fce36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T02:23:41.504070Z",
     "iopub.status.busy": "2025-01-09T02:23:41.503866Z",
     "iopub.status.idle": "2025-01-09T02:23:42.492342Z",
     "shell.execute_reply": "2025-01-09T02:23:42.491938Z",
     "shell.execute_reply.started": "2025-01-09T02:23:41.504054Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The human heart is a muscular organ that pumps blood throughout the body, supplying oxygen and nutrients to tissues and organs. It also helps to regulate blood pressure and maintain blood flow to the brain and other vital organs.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt=\"explain the function of human heart\"\n",
    "generate(model, prompt, tokenizer, max_new_tokens=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2aedf79d-e9ad-4c9e-b31a-d7d3853c6df7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T02:50:20.221903Z",
     "iopub.status.busy": "2025-01-09T02:50:20.221696Z",
     "iopub.status.idle": "2025-01-09T02:50:26.240484Z",
     "shell.execute_reply": "2025-01-09T02:50:26.239854Z",
     "shell.execute_reply.started": "2025-01-09T02:50:20.221888Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as LLAMA32_fine_tuned.pth\n"
     ]
    }
   ],
   "source": [
    "# save model dict\n",
    "model_file_name=\"LLAMA32_fine_tuned.pth\"\n",
    "torch.save(model.state_dict(), model_file_name)\n",
    "print(f\"Model saved as {model_file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78842876-ba0d-4c63-822d-238614aa06a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T02:24:56.690344Z",
     "iopub.status.busy": "2025-01-09T02:24:56.690130Z",
     "iopub.status.idle": "2025-01-09T02:25:32.270523Z",
     "shell.execute_reply": "2025-01-09T02:25:32.269862Z",
     "shell.execute_reply.started": "2025-01-09T02:24:56.690328Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [00:35<00:00,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response saved as test-data-with-response.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# load test data\n",
    "test_data_path=\"instruction-data-val.json\"\n",
    "with open(test_data_path,\"r\") as f:\n",
    "    test_data=json.load(f)\n",
    "\n",
    "for i,entry in tqdm(enumerate(test_data),total=len(test_data)):\n",
    "    generated_text=generate(model, entry[\"instruction\"], tokenizer, max_new_tokens=100)\n",
    "    test_data[i][\"model response\"]=generated_text\n",
    "\n",
    "# write into a file\n",
    "test_data_path=\"test-data-with-response.json\"\n",
    "\n",
    "with open(test_data_path,\"w\") as file:\n",
    "    json.dump(test_data,file, indent=4)\n",
    "print(f\"Response saved as {test_data_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d503f7c2-4bd0-498f-a328-502334c7289c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T02:47:06.015591Z",
     "iopub.status.busy": "2025-01-09T02:47:06.015126Z",
     "iopub.status.idle": "2025-01-09T02:47:06.019093Z",
     "shell.execute_reply": "2025-01-09T02:47:06.018570Z",
     "shell.execute_reply.started": "2025-01-09T02:47:06.015574Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='/notebooks/Llama32-finetune/LLAMA32_fine_tuned.pt' target='_blank'>/notebooks/Llama32-finetune/LLAMA32_fine_tuned.pt</a><br>"
      ],
      "text/plain": [
       "/notebooks/Llama32-finetune/LLAMA32_fine_tuned.pt"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download file\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# Replace 'filename.ext' with your file name\n",
    "FileLink(\"/notebooks/Llama32-finetune/LLAMA32_fine_tuned.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5ad2e0-6845-49bf-a7b4-c52573faf451",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
